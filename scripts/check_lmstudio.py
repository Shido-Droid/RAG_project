import requests
import sys
import os

# LM Studioã®æ¨™æº–çš„ãªURL
DEFAULT_BASE_URL = "http://10.23.130.252:1234/v1"

def get_wsl_host_ip():
    """WSL2ç’°å¢ƒã®å ´åˆã€Windowsãƒ›ã‚¹ãƒˆã®IPã‚¢ãƒ‰ãƒ¬ã‚¹ã‚’å–å¾—ã™ã‚‹"""
    try:
        with open("/etc/resolv.conf", "r") as f:
            for line in f:
                if line.strip().startswith("nameserver"):
                    ip = line.strip().split()[1]
                    if ip != "127.0.0.53": return ip
    except:
        pass
    return None

def check_server(base_url):
    print(f"æ¥ç¶šç¢ºèªä¸­: {base_url} ... ", end="", flush=True)
    
    # 1. ãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã®å–å¾— (ã‚µãƒ¼ãƒãƒ¼ãŒç”Ÿãã¦ã„ã‚‹ã‹ç¢ºèª)
    try:
        response = requests.get(f"{base_url}/models", timeout=3)
        if response.status_code == 200:
            data = response.json()
            models = data.get('data', [])
            print("âœ… ã‚µãƒ¼ãƒãƒ¼æ¥ç¶š: OK")
            if models:
                print(f"âœ… ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«: {models[0]['id']}")
            else:
                print("âš ï¸ ã‚µãƒ¼ãƒãƒ¼ã¯èµ·å‹•ã—ã¦ã„ã¾ã™ãŒã€ãƒ¢ãƒ‡ãƒ«ãŒãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
            return True
        else:
            print(f"âŒ ã‚µãƒ¼ãƒãƒ¼ã‚¨ãƒ©ãƒ¼: ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚³ãƒ¼ãƒ‰ {response.status_code}")
            return False
    except requests.exceptions.ConnectionError:
        print("âŒ æ¥ç¶šå¤±æ•— (Connection Refused)")
        return False
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
        return False

def check_lmstudio():
    target_url = DEFAULT_BASE_URL
    
    # 1. localhost ãƒã‚§ãƒƒã‚¯
    if not check_server(target_url):
        # 2. WSL2åˆ¤å®š & ãƒ›ã‚¹ãƒˆIPãƒã‚§ãƒƒã‚¯
        host_ip = get_wsl_host_ip()
        if host_ip and host_ip != "127.0.0.1":
            print(f"\n[INFO] localhostã¸ã®æ¥ç¶šã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ›ã‚¹ãƒˆIPã¨æ€ã‚ã‚Œã‚‹ã‚¢ãƒ‰ãƒ¬ã‚¹ ({host_ip}) ã§å†è©¦è¡Œã—ã¾ã™...")
            wsl_url = f"http://{host_ip}:1234/v1"
            if check_server(wsl_url):
                target_url = wsl_url
                print(f"\nğŸ’¡ ãƒ’ãƒ³ãƒˆ: WSL2ã‹ã‚‰æ¥ç¶šã™ã‚‹ãŸã‚ã«ã¯ã€ä»¥ä¸‹ã®ç’°å¢ƒå¤‰æ•°ã‚’è¨­å®šã™ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™:")
                print(f'export LMSTUDIO_URL="{target_url}/chat/completions"')
            else:
                print("\nâš ï¸ ãƒ›ã‚¹ãƒˆIPã¸ã®æ¥ç¶šã‚‚å¤±æ•—ã—ã¾ã—ãŸã€‚")
                print("1. LM Studioã§ 'Start Server' ãŒæŠ¼ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
                print("2. Windowså´ã®ãƒ•ã‚¡ã‚¤ã‚¢ã‚¦ã‚©ãƒ¼ãƒ«è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
                return False
        else:
            return False

    # 3. ãƒãƒ£ãƒƒãƒˆç”Ÿæˆãƒ†ã‚¹ãƒˆ
    print(f"\nãƒãƒ£ãƒƒãƒˆç”Ÿæˆãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œä¸­ ({target_url})...")
    payload = {
        "messages": [
            {"role": "system", "content": "You are a helpful assistant."},
            {"role": "user", "content": "Hello!"}
        ],
        "temperature": 0.7,
        "max_tokens": 10,
        "stream": False
    }
    
    try:
        response = requests.post(f"{target_url}/chat/completions", json=payload, timeout=10)
        if response.status_code == 200:
            content = response.json()['choices'][0]['message']['content']
            print(f"âœ… ç”ŸæˆæˆåŠŸ: {content}")
            return True
        else:
            print(f"âŒ ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {response.text}")
            return False
    except Exception as e:
        print(f"âŒ ç”Ÿæˆãƒ†ã‚¹ãƒˆä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
        return False

if __name__ == "__main__":
    if check_lmstudio():
        print("\nğŸ‰ LM Studio ã¯æ­£å¸¸ã«å‹•ä½œã—ã¦ã„ã¾ã™ï¼")
    else:
        print("\nğŸš« LM Studio ã®è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        sys.exit(1)